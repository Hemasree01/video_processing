{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1953150d-853e-4ad6-8dba-24a397b9d97f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform>=1.16.0\n",
    "!pip install kfp>=1.8.0\n",
    "!pip install google-cloud-storage>=1.44.0\n",
    "!pip install google-cloud-speech>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b276391e-922f-41ee-b7bf-85972e7cb421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /opt/conda/lib/python3.10/site-packages (1.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f6e1f7-037b-408a-8e4a-64e7beb0a593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_8977/2029902502.py:7: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import dsl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "from typing import NamedTuple\n",
    "\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud import speech_v1p1beta1 as speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2753df-042e-4dfc-bbce-93511ad0573c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"resolute-winter-447814-t5\"\n",
    "LOCATION = \"us-central1\"\n",
    "INPUT_BUCKET = \"resolute-winter-447814-t5_input\"\n",
    "OUTPUT_BUCKET = \"resolute-winter-447814-t5_output\"\n",
    "SERVICE_ACCOUNT = \"232486347340-compute@developer.gserviceaccount.com\"\n",
    "INPUT_VIDEO = \"gs://resolute-winter-447814-t5_input/videos/Introducing Yourself - Phrases ( lingoneo.org ).mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f73a25a-dced-4251-8e7b-2c2743de9750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"ffmpeg-python\", \"google-cloud-storage\"],\n",
    ")\n",
    "def extract_audio_from_video(\n",
    "    input_video_gcs_path: str,\n",
    "    output_audio_gcs_path: str\n",
    ") -> str:\n",
    "    \"\"\"Extract MP3 audio from MP4 video.\"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    print(f\"Extracting audio from {input_video_gcs_path} to {output_audio_gcs_path}\")\n",
    "    \n",
    "    # Install FFmpeg directly in the component\n",
    "    print(\"Installing FFmpeg...\")\n",
    "    subprocess.run([\"apt-get\", \"update\", \"-y\"], check=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], check=True)\n",
    "    print(\"FFmpeg installed successfully\")\n",
    "    \n",
    "    # Create temporary directory for processing\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Download video from GCS\n",
    "        storage_client = storage.Client()\n",
    "        \n",
    "        # Parse bucket and blob names\n",
    "        input_path = input_video_gcs_path.replace(\"gs://\", \"\")\n",
    "        bucket_name = input_path.split(\"/\")[0]\n",
    "        blob_name = \"/\".join(input_path.split(\"/\")[1:])\n",
    "        \n",
    "        # Get bucket and blob\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        \n",
    "        # Download to temporary file\n",
    "        local_video_path = os.path.join(temp_dir, os.path.basename(blob_name))\n",
    "        blob.download_to_filename(local_video_path)\n",
    "        print(f\"Video downloaded to {local_video_path}\")\n",
    "        \n",
    "        # Extract audio using FFmpeg\n",
    "        local_audio_path = os.path.join(temp_dir, os.path.splitext(os.path.basename(blob_name))[0] + \".mp3\")\n",
    "        print(f\"Extracting audio to {local_audio_path}\")\n",
    "        \n",
    "        # Using subprocess for FFmpeg\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", local_video_path, \n",
    "            \"-vn\",  # No video\n",
    "            \"-acodec\", \"mp3\",  # MP3 codec\n",
    "            \"-ab\", \"192k\",  # Bitrate\n",
    "            \"-ar\", \"44100\",  # Sample rate\n",
    "            \"-y\",  # Overwrite output file\n",
    "            local_audio_path\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True, capture_output=True)\n",
    "            print(\"Audio extraction completed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"FFmpeg error: {e.stderr.decode()}\")\n",
    "            raise RuntimeError(f\"Failed to extract audio: {e}\")\n",
    "        \n",
    "        # Upload extracted audio to GCS\n",
    "        print(f\"Uploading audio to {output_audio_gcs_path}\")\n",
    "        output_path = output_audio_gcs_path.replace(\"gs://\", \"\")\n",
    "        output_bucket_name = output_path.split(\"/\")[0]\n",
    "        output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "        \n",
    "        output_bucket = storage_client.bucket(output_bucket_name)\n",
    "        output_blob = output_bucket.blob(output_blob_name)\n",
    "        output_blob.upload_from_filename(local_audio_path)\n",
    "        \n",
    "        print(f\"Audio extraction and upload complete\")\n",
    "        \n",
    "        return output_audio_gcs_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe41a668-5c88-47ce-a6f9-97abcb13a14e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import component\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"assemblyai\", \"google-cloud-storage\"],\n",
    ")\n",
    "def transcribe_audio_assemblyai(\n",
    "    audio_gcs_path: str,\n",
    "    output_transcript_gcs_path: str,\n",
    "    assemblyai_api_key: str,\n",
    "    language_code: str = \"en\",\n",
    "     model: str = \"chirp\" # New model parameter with default \"chirp\"\n",
    ") -> str:\n",
    "    \"\"\"Transcribes audio from Google Cloud Storage using AssemblyAI's Chirp model.\"\"\"\n",
    "\n",
    "    import os\n",
    "    import json\n",
    "    import assemblyai as aai\n",
    "    from google.cloud import storage\n",
    "    import tempfile\n",
    "\n",
    "    print(f\"Transcribing audio from {audio_gcs_path} using AssemblyAI Chirp to {output_transcript_gcs_path}\")\n",
    "\n",
    "    try:\n",
    "        # Initialize GCS client\n",
    "        storage_client = storage.Client()\n",
    "\n",
    "        # Create a temporary directory\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            # Construct local audio path\n",
    "            local_audio_path = os.path.join(temp_dir, \"audio.mp3\")\n",
    "\n",
    "            # Download the audio from GCS\n",
    "            print(f\"Downloading {audio_gcs_path} to {local_audio_path}\")\n",
    "            #---------GCS VALIDATION------\n",
    "            input_path = audio_gcs_path.replace(\"gs://\", \"\")\n",
    "            if not input_path:\n",
    "                raise ValueError(\"Invalid audio_gcs_path: cannot be empty.\")\n",
    "\n",
    "            input_parts = input_path.split(\"/\")\n",
    "\n",
    "            if len(input_parts) < 2:\n",
    "                raise ValueError(\n",
    "                    \"Invalid audio_gcs_path: must be in the format \"\n",
    "                    \"gs://bucket-name/path/to/audio.mp3\"\n",
    "                )\n",
    "\n",
    "            bucket_name = input_parts[0]\n",
    "            blob_name = \"/\".join(input_parts[1:])\n",
    "\n",
    "\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(blob_name)\n",
    "            blob.download_to_filename(local_audio_path) #Download the file\n",
    "            print(f\"Audio downloaded successfully to {local_audio_path}\")\n",
    "            #---------------------------\n",
    "\n",
    "            # Configure AssemblyAI\n",
    "            aai.settings.api_key = assemblyai_api_key\n",
    "            transcriber = aai.Transcriber()\n",
    "            transcriber.model = model #Setting transcribe Object\n",
    "            # Configuration for AssemblyAI\n",
    "            config = aai.TranscriptionConfig(\n",
    "                speaker_labels=True,  # Enable speaker diarization\n",
    "                language_code=language_code # Specify the language\n",
    "            )\n",
    "\n",
    "            # Transcribe the *local* audio file\n",
    "            print(f\"Transcribing local file {local_audio_path}\")\n",
    "            transcript = transcriber.transcribe(local_audio_path, config)\n",
    "\n",
    "            if transcript:\n",
    "                print(\"Transcript Status:\", transcript.status)\n",
    "                transcript_data = {\n",
    "                    \"text\": transcript.text,\n",
    "                    \"status\": transcript.status,\n",
    "                    \"words\": []  #Add the word-level info if needed in the transcript_data\n",
    "                }\n",
    "\n",
    "                #If you need word-level information (times, confidences):\n",
    "                if transcript.words:\n",
    "                    for word in transcript.words:\n",
    "                        word_data = {\n",
    "                            \"text\": word.text,\n",
    "                            \"confidence\": word.confidence,\n",
    "                            \"speaker\": word.speaker\n",
    "                        }\n",
    "                        if hasattr(word, \"start\"):\n",
    "                            word_data[\"start\"] = word.start\n",
    "                        else:\n",
    "                            word_data[\"start\"] = None\n",
    "                        if hasattr(word, \"end\"):\n",
    "                            word_data[\"end\"] = word.end\n",
    "                        else:\n",
    "                            word_data[\"end\"] = None\n",
    "\n",
    "                        transcript_data[\"words\"].append(word_data)\n",
    "\n",
    "                # Upload transcript to GCS\n",
    "                # Ensure storage_client is initialized only once\n",
    "                with tempfile.TemporaryDirectory() as temp_dir2:\n",
    "                    local_transcript_path = os.path.join(temp_dir2, \"transcript.json\")\n",
    "\n",
    "                    with open(local_transcript_path, \"w\") as f:\n",
    "                        json.dump(transcript_data, f, indent=2)\n",
    "\n",
    "                    # Upload to GCS\n",
    "                    print(f\"Uploading transcript to {output_transcript_gcs_path}\")\n",
    "\n",
    "                    output_path = output_transcript_gcs_path.replace(\"gs://\", \"\")\n",
    "\n",
    "                    if not output_path:\n",
    "                        raise ValueError(\"Invalid output_transcript_gcs_path: cannot be empty.\")\n",
    "\n",
    "                    parts = output_path.split(\"/\")\n",
    "\n",
    "                    if len(parts) < 2:\n",
    "                        raise ValueError(\n",
    "                            \"Invalid output_transcript_gcs_path: must be in the format \"\n",
    "                            \"gs://bucket-name/path/to/transcript.json\"\n",
    "                        )\n",
    "\n",
    "                    output_bucket_name = parts[0]\n",
    "                    output_blob_name = \"/\".join(parts[1:])\n",
    "\n",
    "                    output_bucket = storage_client.bucket(output_bucket_name)\n",
    "                    output_blob = output_bucket.blob(output_blob_name)\n",
    "\n",
    "                    print(f\"Attempting to upload {local_transcript_path} to {output_transcript_gcs_path}\")\n",
    "                    output_blob.upload_from_filename(local_transcript_path)\n",
    "                    print(f\"Upload completed successfully\")\n",
    "\n",
    "\n",
    "                print(f\"Transcription saved to {output_transcript_gcs_path}\")\n",
    "\n",
    "                return output_transcript_gcs_path\n",
    "\n",
    "            else:\n",
    "                print(\"Transcription failed.\")\n",
    "                raise ValueError(\"AssemblyAI transcription failed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise e # Re-raise the exception for KFP to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69e0c74a-5f92-4bd7-a811-34d93a0a6e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"google-cloud-storage\"],\n",
    ")\n",
    "def generate_subtitles(\n",
    "    transcript_gcs_path: str,\n",
    "    output_subtitles_gcs_path: str,\n",
    "    max_chars_per_line: int = 42\n",
    ") -> str:\n",
    "    \"\"\"Generate an SRT file that formats words into sentences while preserving exact timing.\"\"\"\n",
    "    \n",
    "    import os\n",
    "    import json\n",
    "    import tempfile\n",
    "    import re\n",
    "    from google.cloud import storage\n",
    "    from collections import defaultdict\n",
    "\n",
    "    print(f\"Generating sentence-based subtitles from {transcript_gcs_path} to {output_subtitles_gcs_path}\")\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    try:\n",
    "        # Download transcript from GCS\n",
    "        input_path = transcript_gcs_path.replace(\"gs://\", \"\")\n",
    "        bucket_name = input_path.split(\"/\")[0]\n",
    "        blob_name = \"/\".join(input_path.split(\"/\")[1:])\n",
    "        \n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        \n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            local_transcript_path = os.path.join(temp_dir, \"transcript.json\")\n",
    "            try:\n",
    "                blob.download_to_filename(local_transcript_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading transcript: {e}\")\n",
    "                raise\n",
    "            \n",
    "            # Load transcript\n",
    "            try:\n",
    "                with open(local_transcript_path, \"r\") as f:\n",
    "                    transcript_data = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading transcript JSON: {e}\")\n",
    "                raise\n",
    "                \n",
    "            words = transcript_data.get(\"words\", [])\n",
    "            print(f\"Number of words in transcript: {len(words)}\")  # Check number of words\n",
    "            if not words:\n",
    "                print(\"No word-level timing information found in transcript\")\n",
    "                return None\n",
    "\n",
    "            def format_time(milliseconds):\n",
    "                \"\"\"Convert milliseconds to SRT time format (HH:MM:SS,mmm)\"\"\"\n",
    "                seconds = float(milliseconds) / 1000  # Convert to seconds\n",
    "                hours = int(seconds // 3600)\n",
    "                minutes = int((seconds % 3600) // 60)\n",
    "                seconds = seconds % 60\n",
    "                return f\"{hours:02d}:{minutes:02d}:{seconds:06.3f}\".replace(\".\", \",\")\n",
    "        \n",
    "            # Function to group words into sentences based on punctuation\n",
    "            def is_sentence_end(word):\n",
    "                \"\"\"Check if a word marks the end of a sentence.\"\"\"\n",
    "                return bool(re.search(r'[.!?]$', word))\n",
    "            \n",
    "            srt_content = \"\"\n",
    "            subtitle_count = 1\n",
    "            i = 0\n",
    "            error_count = defaultdict(int) # For Logging statistics\n",
    "            while i < len(words):\n",
    "                # Use the correct key name \"start\" and \"end\" and require text\n",
    "                if \"start\" not in words[i] or \"end\" not in words[i] or \"text\" not in words[i]:\n",
    "                    print(f\"Skipping word at index {i} due to missing timing/text information.\")\n",
    "                    error_count[\"missing\"] += 1 # Keep track of the issue\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                start_time = words[i][\"start\"]\n",
    "                end_time = words[i][\"end\"]\n",
    "                \n",
    "                sentence_words = []\n",
    "                \n",
    "                while i < len(words):\n",
    "                    word = words[i]\n",
    "                    if \"start\" not in words[i] or \"end\" not in words[i] or \"text\" not in words[i]:\n",
    "                        print(f\"Skipping word at index {i} due to missing timing/text information inside inner loop.\")\n",
    "                        error_count[\"inner_missing\"] += 1  # Track errors in the inner loop\n",
    "                        i += 1\n",
    "                        break\n",
    "\n",
    "                    sentence_words.append(word[\"text\"]) #Use text\n",
    "                    end_time = word[\"end\"]  # Use \"end\"\n",
    "\n",
    "                    if is_sentence_end(word[\"text\"]) or i == len(words) - 1:  # use \"text\"\n",
    "                        break\n",
    "                    \n",
    "                    i += 1\n",
    "\n",
    "                i += 1  # Move to the next word for the next subtitle\n",
    "\n",
    "                formatted_lines = []\n",
    "                current_line = []\n",
    "                current_line_chars = 0\n",
    "\n",
    "                for word in sentence_words:\n",
    "                    if current_line_chars + len(word) + 1 > max_chars_per_line and current_line:\n",
    "                        formatted_lines.append(\" \".join(current_line))\n",
    "                        current_line = [word]\n",
    "                        current_line_chars = len(word)\n",
    "                    else:\n",
    "                        current_line.append(word)\n",
    "                        current_line_chars += len(word) + (1 if current_line_chars > 0 else 0)\n",
    "\n",
    "                if current_line:\n",
    "                    formatted_lines.append(\" \".join(current_line))\n",
    "\n",
    "                srt_content += f\"{subtitle_count}\\n\"\n",
    "                srt_content += f\"{format_time(start_time)} --> {format_time(end_time)}\\n\"\n",
    "                srt_content += \"\\n\".join(formatted_lines) + \"\\n\\n\"\n",
    "                subtitle_count += 1\n",
    "\n",
    "            print(f\"Final SRT Statistics: {error_count}\") # Report\n",
    "            local_srt_path = os.path.join(temp_dir, \"subtitles.srt\")\n",
    "            with open(local_srt_path, \"w\") as f:\n",
    "                f.write(srt_content)\n",
    "\n",
    "            output_path = output_subtitles_gcs_path.replace(\"gs://\", \"\")\n",
    "            output_bucket_name = output_path.split(\"/\")[0]\n",
    "            output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "\n",
    "            output_bucket = storage_client.bucket(output_bucket_name)\n",
    "            output_blob = output_bucket.blob(output_blob_name)\n",
    "            output_blob.upload_from_filename(local_srt_path)\n",
    "\n",
    "            print(f\"Generated precise sentence-based subtitles and uploaded to {output_subtitles_gcs_path}\")\n",
    "\n",
    "            return output_subtitles_gcs_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00846abe-83d8-4e26-88a7-a88123f91802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"ffmpeg-python\", \"google-cloud-storage\"],\n",
    ")\n",
    "def overlay_subtitles_on_video(\n",
    "    input_video_gcs_path: str,\n",
    "    subtitles_gcs_path: str,\n",
    "    output_video_gcs_path: str,\n",
    "    font_size: int = 48,\n",
    "    font_color: str = \"white\"\n",
    ") -> str:\n",
    "    \"\"\"Overlay SRT subtitles on video ensuring exact sentence-based sync.\"\"\"\n",
    "    \n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from google.cloud import storage\n",
    "\n",
    "    print(f\"Overlaying subtitles from {subtitles_gcs_path} on {input_video_gcs_path}\")\n",
    "\n",
    "    # Install FFmpeg\n",
    "    subprocess.run([\"apt-get\", \"update\", \"-y\"], check=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], check=True)\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Download video from GCS\n",
    "        input_video_path = input_video_gcs_path.replace(\"gs://\", \"\")\n",
    "        video_bucket_name = input_video_path.split(\"/\")[0]\n",
    "        video_blob_name = \"/\".join(input_video_path.split(\"/\")[1:])\n",
    "        \n",
    "        video_bucket = storage_client.bucket(video_bucket_name)\n",
    "        video_blob = video_bucket.blob(video_blob_name)\n",
    "        \n",
    "        local_video_path = os.path.join(temp_dir, os.path.basename(video_blob_name))\n",
    "        video_blob.download_to_filename(local_video_path)\n",
    "\n",
    "        # Download subtitles from GCS\n",
    "        subtitles_path = subtitles_gcs_path.replace(\"gs://\", \"\")\n",
    "        subtitles_bucket_name = subtitles_path.split(\"/\")[0]\n",
    "        subtitles_blob_name = \"/\".join(subtitles_path.split(\"/\")[1:])\n",
    "        \n",
    "        subtitles_bucket = storage_client.bucket(subtitles_bucket_name)\n",
    "        subtitles_blob = subtitles_bucket.blob(subtitles_blob_name)\n",
    "        \n",
    "        local_subtitles_path = os.path.join(temp_dir, \"subtitles.srt\")\n",
    "        subtitles_blob.download_to_filename(local_subtitles_path)\n",
    "\n",
    "        # Output video path\n",
    "        local_output_video_path = os.path.join(\n",
    "            temp_dir, \n",
    "            f\"{os.path.splitext(os.path.basename(video_blob_name))[0]}_with_subtitles.mp4\"\n",
    "        )\n",
    "\n",
    "        # Overlay subtitles using FFmpeg with exact timing\n",
    "        print(\"Overlaying subtitles with sentence-based exact sync\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", local_video_path,\n",
    "            \"-vf\", f\"subtitles={local_subtitles_path}\",\n",
    "            \"-c:a\", \"copy\",  # Preserve original audio\n",
    "            \"-y\",  # Overwrite output file\n",
    "            local_output_video_path\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True, capture_output=True)\n",
    "            print(\"Subtitle overlay completed successfully with exact sentence sync\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"FFmpeg error: {e.stderr.decode()}\")\n",
    "            raise RuntimeError(\"Failed to overlay subtitles with exact sync\")\n",
    "\n",
    "        # Upload output video to GCS\n",
    "        output_path = output_video_gcs_path.replace(\"gs://\", \"\")\n",
    "        output_bucket_name = output_path.split(\"/\")[0]\n",
    "        output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "        \n",
    "        output_bucket = storage_client.bucket(output_bucket_name)\n",
    "        output_blob = output_bucket.blob(output_blob_name)\n",
    "        output_blob.upload_from_filename(local_output_video_path)\n",
    "\n",
    "        print(f\"Video with exact subtitles uploaded to {output_video_gcs_path}\")\n",
    "        \n",
    "        return output_video_gcs_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14f77d10-770e-487a-91e9-87c98add3218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline compiled successfully to video_processing_pipeline.json\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"video-processing-pipeline\",\n",
    "    description=\"A pipeline that processes MP4 videos, extracts audio, generates transcriptions, and overlays subtitles\"\n",
    ")\n",
    "def video_processing_pipeline(\n",
    "    input_video_gcs_path: str,\n",
    "    output_bucket: str,\n",
    "    assemblyai_api_key: str,\n",
    "    language_code: str = \"en\",\n",
    "    model: str = \"chirp\"\n",
    ") -> NamedTuple('Outputs', [('output_video', str)]):  # Add this return type annotation\n",
    "    \"\"\"Pipeline that processes video files with subtitle generation.\"\"\"\n",
    "    \n",
    "    # Define output paths\n",
    "    video_basename = \"video\"  # Using fixed names to avoid string manipulation in pipeline\n",
    "    \n",
    "    output_audio_gcs_path = f\"gs://{output_bucket}/output/audio/{video_basename}.mp3\"\n",
    "    output_transcript_gcs_path = f\"gs://{output_bucket}/output/transcripts/{video_basename}.json\"\n",
    "    output_subtitles_gcs_path = f\"gs://{output_bucket}/output/subtitles/{video_basename}.srt\"\n",
    "    output_video_gcs_path = f\"gs://{output_bucket}/output/videos/{video_basename}_with_subtitles.mp4\"\n",
    "    \n",
    "    # Step 1: Extract audio from video\n",
    "    extract_task = extract_audio_from_video(\n",
    "        input_video_gcs_path=input_video_gcs_path,\n",
    "        output_audio_gcs_path=output_audio_gcs_path\n",
    "    )\n",
    "    \n",
    "    # Step 2: Transcribe audio to text\n",
    "    transcribe_task = transcribe_audio_assemblyai(\n",
    "        audio_gcs_path=extract_task.output,\n",
    "        assemblyai_api_key=assemblyai_api_key,\n",
    "        output_transcript_gcs_path=output_transcript_gcs_path,\n",
    "        language_code=language_code,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Step 3: Generate subtitles from transcription\n",
    "    subtitles_task = generate_subtitles(\n",
    "        transcript_gcs_path=transcribe_task.output,\n",
    "        output_subtitles_gcs_path=output_subtitles_gcs_path\n",
    "    )\n",
    "    \n",
    "    # Step 4: Overlay subtitles on video\n",
    "    overlay_task = overlay_subtitles_on_video(\n",
    "        input_video_gcs_path=input_video_gcs_path,\n",
    "        subtitles_gcs_path=subtitles_task.output,\n",
    "        output_video_gcs_path=output_video_gcs_path\n",
    "    )\n",
    "    \n",
    "    # Return the final output with proper naming\n",
    "    return NamedTuple('Outputs', [('output_video', str)])(overlay_task.output)\n",
    "\n",
    "# STEP 6: Compile the Pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=video_processing_pipeline,\n",
    "    package_path=\"video_processing_pipeline.json\"\n",
    ")\n",
    "\n",
    "print(\"Pipeline compiled successfully to video_processing_pipeline.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b66478-479b-4112-9e7c-744fab60c45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
