{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe8c2c6-fd8f-4333-bb60-89422f3fb27c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform>=1.16.0\n",
    "!pip install kfp>=1.8.0\n",
    "!pip install google-cloud-storage>=1.44.0\n",
    "!pip install google-cloud-speech>=2.0.0\n",
    "!apt-get update && apt-get install -y ffmpeg\n",
    "!pip install ffmpeg-python>=0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250c1308-e22c-4e36-81e2-d525e33546bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6127 sha256=7ba7123e07899237419ea0e81598a588395955eb4ad676f69f2a05782d7278ad\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef803af-0554-4ade-bd0e-eb70cb9007da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_4391/2029902502.py:7: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import dsl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "from typing import NamedTuple\n",
    "\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud import speech_v1p1beta1 as speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13320ef3-0a83-45ce-82e8-7488c2afa859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"resolute-winter-447814-t5\"\n",
    "LOCATION = \"us-central1\"\n",
    "INPUT_BUCKET = \"resolute-winter-447814-t5_input\"\n",
    "OUTPUT_BUCKET = \"resolute-winter-447814-t5_output\"\n",
    "SERVICE_ACCOUNT = \"232486347340-compute@developer.gserviceaccount.com\"\n",
    "INPUT_VIDEO = \"gs://resolute-winter-447814-t5_input/videos/Introducing Yourself - Phrases ( lingoneo.org ).mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8763113e-0dd5-45a9-89c7-f4e8d0a87054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"ffmpeg-python\", \"google-cloud-storage\"],\n",
    ")\n",
    "def extract_audio_from_video(\n",
    "    input_video_gcs_path: str,\n",
    "    output_audio_gcs_path: str\n",
    ") -> str:\n",
    "    \"\"\"Extract MP3 audio from MP4 video.\"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    print(f\"Extracting audio from {input_video_gcs_path} to {output_audio_gcs_path}\")\n",
    "    \n",
    "    # Install FFmpeg directly in the component\n",
    "    print(\"Installing FFmpeg...\")\n",
    "    subprocess.run([\"apt-get\", \"update\", \"-y\"], check=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], check=True)\n",
    "    print(\"FFmpeg installed successfully\")\n",
    "    \n",
    "    # Create temporary directory for processing\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Download video from GCS\n",
    "        storage_client = storage.Client()\n",
    "        \n",
    "        # Parse bucket and blob names\n",
    "        input_path = input_video_gcs_path.replace(\"gs://\", \"\")\n",
    "        bucket_name = input_path.split(\"/\")[0]\n",
    "        blob_name = \"/\".join(input_path.split(\"/\")[1:])\n",
    "        \n",
    "        # Get bucket and blob\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        \n",
    "        # Download to temporary file\n",
    "        local_video_path = os.path.join(temp_dir, os.path.basename(blob_name))\n",
    "        blob.download_to_filename(local_video_path)\n",
    "        print(f\"Video downloaded to {local_video_path}\")\n",
    "        \n",
    "        # Extract audio using FFmpeg\n",
    "        local_audio_path = os.path.join(temp_dir, os.path.splitext(os.path.basename(blob_name))[0] + \".mp3\")\n",
    "        print(f\"Extracting audio to {local_audio_path}\")\n",
    "        \n",
    "        # Using subprocess for FFmpeg\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", local_video_path, \n",
    "            \"-vn\",  # No video\n",
    "            \"-acodec\", \"mp3\",  # MP3 codec\n",
    "            \"-ab\", \"192k\",  # Bitrate\n",
    "            \"-ar\", \"44100\",  # Sample rate\n",
    "            \"-y\",  # Overwrite output file\n",
    "            local_audio_path\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True, capture_output=True)\n",
    "            print(\"Audio extraction completed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"FFmpeg error: {e.stderr.decode()}\")\n",
    "            raise RuntimeError(f\"Failed to extract audio: {e}\")\n",
    "        \n",
    "        # Upload extracted audio to GCS\n",
    "        print(f\"Uploading audio to {output_audio_gcs_path}\")\n",
    "        output_path = output_audio_gcs_path.replace(\"gs://\", \"\")\n",
    "        output_bucket_name = output_path.split(\"/\")[0]\n",
    "        output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "        \n",
    "        output_bucket = storage_client.bucket(output_bucket_name)\n",
    "        output_blob = output_bucket.blob(output_blob_name)\n",
    "        output_blob.upload_from_filename(local_audio_path)\n",
    "        \n",
    "        print(f\"Audio extraction and upload complete\")\n",
    "        \n",
    "        return output_audio_gcs_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e939a8af-878d-4e76-9f49-af16c36de806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"google-cloud-speech\", \"google-cloud-storage\"],\n",
    ")\n",
    "def transcribe_audio(\n",
    "    audio_gcs_path: str,\n",
    "    output_transcript_gcs_path: str,\n",
    "    language_code: str = \"en-US\"\n",
    ") -> str:\n",
    "    \"\"\"Transcribe MP3 audio to text using Google Cloud Speech-to-Text.\"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    import tempfile\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    print(f\"Transcribing audio from {audio_gcs_path} to {output_transcript_gcs_path}\")\n",
    "    \n",
    "    # Create Speech-to-Text client\n",
    "    speech_client = speech.SpeechClient()\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Configure the speech recognition request\n",
    "    audio = speech.RecognitionAudio(uri=audio_gcs_path)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.MP3,\n",
    "        sample_rate_hertz=44100,\n",
    "        language_code=language_code,\n",
    "        enable_word_time_offsets=True,\n",
    "        enable_automatic_punctuation=True,\n",
    "        model=\"video\"  # Use the video model for better accuracy with video content\n",
    "    )\n",
    "    \n",
    "    # Start the long-running recognition operation\n",
    "    print(\"Starting transcription (this may take a while)...\")\n",
    "    operation = speech_client.long_running_recognize(config=config, audio=audio)\n",
    "    \n",
    "    # Wait for operation to complete\n",
    "    response = operation.result(timeout=600)  # Increased timeout for longer audio\n",
    "    print(\"Transcription completed\")\n",
    "    \n",
    "    # Process the response\n",
    "    transcript_data = {\n",
    "        \"transcript\": \"\",\n",
    "        \"words\": [],\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        transcript_data[\"transcript\"] += alternative.transcript + \" \"\n",
    "        \n",
    "        # Add detailed results\n",
    "        result_data = {\n",
    "            \"transcript\": alternative.transcript,\n",
    "            \"confidence\": alternative.confidence,\n",
    "            \"words\": []\n",
    "        }\n",
    "        \n",
    "        # Add word-level information if available\n",
    "        for word_info in alternative.words:\n",
    "            # Handle different response formats (timedelta vs seconds/nanos)\n",
    "            if hasattr(word_info.start_time, 'seconds') and hasattr(word_info.start_time, 'nanos'):\n",
    "                # Old format with seconds and nanos\n",
    "                start_seconds = f\"{word_info.start_time.seconds}.{word_info.start_time.nanos//1000000:03d}\"\n",
    "                end_seconds = f\"{word_info.end_time.seconds}.{word_info.end_time.nanos//1000000:03d}\"\n",
    "            else:\n",
    "                # New format with timedelta\n",
    "                start_seconds = str(word_info.start_time.total_seconds())\n",
    "                end_seconds = str(word_info.end_time.total_seconds())\n",
    "            \n",
    "            word_data = {\n",
    "                \"word\": word_info.word,\n",
    "                \"start_time\": start_seconds,\n",
    "                \"end_time\": end_seconds\n",
    "            }\n",
    "            transcript_data[\"words\"].append(word_data)\n",
    "            result_data[\"words\"].append(word_data)\n",
    "        \n",
    "        transcript_data[\"results\"].append(result_data)\n",
    "    \n",
    "    # Save transcript to GCS\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        local_transcript_path = os.path.join(temp_dir, \"transcript.json\")\n",
    "        \n",
    "        with open(local_transcript_path, \"w\") as f:\n",
    "            json.dump(transcript_data, f, indent=2)\n",
    "        \n",
    "        # Upload to GCS\n",
    "        print(f\"Uploading transcript to {output_transcript_gcs_path}\")\n",
    "        output_path = output_transcript_gcs_path.replace(\"gs://\", \"\")\n",
    "        output_bucket_name = output_path.split(\"/\")[0]\n",
    "        output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "        \n",
    "        output_bucket = storage_client.bucket(output_bucket_name)\n",
    "        output_blob = output_bucket.blob(output_blob_name)\n",
    "        output_blob.upload_from_filename(local_transcript_path)\n",
    "    \n",
    "    print(f\"Transcription saved to {output_transcript_gcs_path}\")\n",
    "    \n",
    "    return output_transcript_gcs_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f16134b1-ae64-4c8c-b147-01ba4e3dca91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"google-cloud-storage\"],\n",
    ")\n",
    "def generate_subtitles(\n",
    "    transcript_gcs_path: str,\n",
    "    output_subtitles_gcs_path: str,\n",
    "    max_chars_per_line: int = 42,\n",
    "    max_lines_per_subtitle: int = 2\n",
    ") -> str:\n",
    "    \"\"\"Generate SRT subtitles from transcription data.\"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    import tempfile\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    print(f\"Generating subtitles from {transcript_gcs_path} to {output_subtitles_gcs_path}\")\n",
    "    \n",
    "    # Create Storage client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Download transcript from GCS\n",
    "    input_path = transcript_gcs_path.replace(\"gs://\", \"\")\n",
    "    bucket_name = input_path.split(\"/\")[0]\n",
    "    blob_name = \"/\".join(input_path.split(\"/\")[1:])\n",
    "    \n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        local_transcript_path = os.path.join(temp_dir, \"transcript.json\")\n",
    "        blob.download_to_filename(local_transcript_path)\n",
    "        \n",
    "        # Load transcript data\n",
    "        with open(local_transcript_path, \"r\") as f:\n",
    "            transcript_data = json.load(f)\n",
    "        \n",
    "        # Generate SRT content\n",
    "        print(\"Generating SRT subtitles\")\n",
    "        \n",
    "        def format_time(time_str):\n",
    "            \"\"\"Convert seconds to SRT time format (HH:MM:SS,mmm)\"\"\"\n",
    "            seconds = float(time_str)\n",
    "            hours = int(seconds // 3600)\n",
    "            minutes = int((seconds % 3600) // 60)\n",
    "            seconds = seconds % 60\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:06.3f}\".replace(\".\", \",\")\n",
    "        \n",
    "        words = transcript_data.get(\"words\", [])\n",
    "        if not words:\n",
    "            print(\"No word-level timing information found in transcript\")\n",
    "            return None\n",
    "        \n",
    "        # Group words into subtitles\n",
    "        srt_content = \"\"\n",
    "        subtitle_count = 1\n",
    "        current_subtitle = []\n",
    "        current_line = []\n",
    "        current_line_chars = 0\n",
    "        current_subtitle_lines = 0\n",
    "        start_time = None\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            word_text = word[\"word\"]\n",
    "            word_start = word[\"start_time\"]\n",
    "            word_end = word[\"end_time\"]\n",
    "            \n",
    "            # Initialize start time if this is the first word\n",
    "            if start_time is None:\n",
    "                start_time = word_start\n",
    "            \n",
    "            # Check if adding this word would exceed the max chars per line\n",
    "            if current_line_chars + len(word_text) + 1 > max_chars_per_line:\n",
    "                # Line is full, add it to current subtitle\n",
    "                current_subtitle.append(\" \".join(current_line))\n",
    "                current_line = [word_text]\n",
    "                current_line_chars = len(word_text)\n",
    "                current_subtitle_lines += 1\n",
    "            else:\n",
    "                # Add word to current line\n",
    "                current_line.append(word_text)\n",
    "                current_line_chars += len(word_text) + 1\n",
    "            \n",
    "            # Check if we need to finalize the current subtitle\n",
    "            is_last_word = i == len(words) - 1\n",
    "            \n",
    "            if current_subtitle_lines >= max_lines_per_subtitle or is_last_word:\n",
    "                # Add the current line if it's not empty\n",
    "                if current_line:\n",
    "                    current_subtitle.append(\" \".join(current_line))\n",
    "                \n",
    "                # Create the subtitle entry\n",
    "                if current_subtitle:\n",
    "                    srt_content += f\"{subtitle_count}\\n\"\n",
    "                    srt_content += f\"{format_time(start_time)} --> {format_time(word_end)}\\n\"\n",
    "                    srt_content += \"\\n\".join(current_subtitle) + \"\\n\\n\"\n",
    "                    subtitle_count += 1\n",
    "                \n",
    "                # Reset for next subtitle\n",
    "                current_subtitle = []\n",
    "                current_line = []\n",
    "                current_line_chars = 0\n",
    "                current_subtitle_lines = 0\n",
    "                start_time = None if not is_last_word else start_time\n",
    "        \n",
    "        # Save SRT file\n",
    "        local_srt_path = os.path.join(temp_dir, \"subtitles.srt\")\n",
    "        with open(local_srt_path, \"w\") as f:\n",
    "            f.write(srt_content)\n",
    "        \n",
    "        # Upload to GCS\n",
    "        print(f\"Uploading subtitles to {output_subtitles_gcs_path}\")\n",
    "        output_path = output_subtitles_gcs_path.replace(\"gs://\", \"\")\n",
    "        output_bucket_name = output_path.split(\"/\")[0]\n",
    "        output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "        \n",
    "        output_bucket = storage_client.bucket(output_bucket_name)\n",
    "        output_blob = output_bucket.blob(output_blob_name)\n",
    "        output_blob.upload_from_filename(local_srt_path)\n",
    "    \n",
    "    print(f\"Generated {subtitle_count-1} subtitles and saved to {output_subtitles_gcs_path}\")\n",
    "    \n",
    "    return output_subtitles_gcs_path\n",
    "\n",
    "# Component 4: Overlay Subtitles on Video\n",
    "@dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"ffmpeg-python\", \"google-cloud-storage\"],\n",
    ")\n",
    "def overlay_subtitles_on_video(\n",
    "    input_video_gcs_path: str,\n",
    "    subtitles_gcs_path: str,\n",
    "    output_video_gcs_path: str,\n",
    "    font_size: int = 24,\n",
    "    font_color: str = \"white\"\n",
    ") -> str:\n",
    "    \"\"\"Overlay SRT subtitles on MP4 video.\"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    print(f\"Overlaying subtitles from {subtitles_gcs_path} on {input_video_gcs_path}\")\n",
    "    \n",
    "    # Install FFmpeg directly in the component\n",
    "    print(\"Installing FFmpeg...\")\n",
    "    subprocess.run([\"apt-get\", \"update\", \"-y\"], check=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], check=True)\n",
    "    print(\"FFmpeg installed successfully\")\n",
    "    \n",
    "    # Create Storage client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Create temporary directory for processing\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Download video from GCS\n",
    "        input_video_path = input_video_gcs_path.replace(\"gs://\", \"\")\n",
    "        video_bucket_name = input_video_path.split(\"/\")[0]\n",
    "        video_blob_name = \"/\".join(input_video_path.split(\"/\")[1:])\n",
    "        \n",
    "        video_bucket = storage_client.bucket(video_bucket_name)\n",
    "        video_blob = video_bucket.blob(video_blob_name)\n",
    "        \n",
    "        local_video_path = os.path.join(temp_dir, os.path.basename(video_blob_name))\n",
    "        video_blob.download_to_filename(local_video_path)\n",
    "        \n",
    "        # Download subtitles from GCS\n",
    "        subtitles_path = subtitles_gcs_path.replace(\"gs://\", \"\")\n",
    "        subtitles_bucket_name = subtitles_path.split(\"/\")[0]\n",
    "        subtitles_blob_name = \"/\".join(subtitles_path.split(\"/\")[1:])\n",
    "        \n",
    "        subtitles_bucket = storage_client.bucket(subtitles_bucket_name)\n",
    "        subtitles_blob = subtitles_bucket.blob(subtitles_blob_name)\n",
    "        \n",
    "        local_subtitles_path = os.path.join(temp_dir, \"subtitles.srt\")\n",
    "        subtitles_blob.download_to_filename(local_subtitles_path)\n",
    "        \n",
    "        # Output video path\n",
    "        local_output_video_path = os.path.join(\n",
    "            temp_dir, \n",
    "            f\"{os.path.splitext(os.path.basename(video_blob_name))[0]}_with_subtitles.mp4\"\n",
    "        )\n",
    "        \n",
    "        # Overlay subtitles using FFmpeg\n",
    "        print(\"Overlaying subtitles on video\")\n",
    "        \n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", local_video_path,\n",
    "            \"-vf\", f\"subtitles={local_subtitles_path}:force_style='FontSize={font_size},PrimaryColour=&H{font_color}'\",\n",
    "            \"-c:a\", \"copy\",  # Copy audio stream\n",
    "            \"-y\",  # Overwrite output file\n",
    "            local_output_video_path\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True, capture_output=True)\n",
    "            print(\"Subtitle overlay completed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"FFmpeg error: {e.stderr.decode()}\")\n",
    "            raise RuntimeError(f\"Failed to overlay subtitles: {e}\")\n",
    "        \n",
    "        # Upload output video to GCS\n",
    "        print(f\"Uploading video with subtitles to {output_video_gcs_path}\")\n",
    "        output_path = output_video_gcs_path.replace(\"gs://\", \"\")\n",
    "        output_bucket_name = output_path.split(\"/\")[0]\n",
    "        output_blob_name = \"/\".join(output_path.split(\"/\")[1:])\n",
    "        \n",
    "        output_bucket = storage_client.bucket(output_bucket_name)\n",
    "        output_blob = output_bucket.blob(output_blob_name)\n",
    "        output_blob.upload_from_filename(local_output_video_path)\n",
    "        \n",
    "        print(f\"Video with subtitles uploaded to {output_video_gcs_path}\")\n",
    "        \n",
    "        return output_video_gcs_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aea54a7f-64f3-49aa-b599-4777613ccb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline compiled successfully to video_processing_pipeline.json\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"video-processing-pipeline\",\n",
    "    description=\"A pipeline that processes MP4 videos, extracts audio, generates transcriptions, and overlays subtitles\"\n",
    ")\n",
    "def video_processing_pipeline(\n",
    "    input_video_gcs_path: str,\n",
    "    output_bucket: str,\n",
    "    language_code: str = \"en-US\"\n",
    ") -> NamedTuple('Outputs', [('output_video', str)]):  # Add this return type annotation\n",
    "    \"\"\"Pipeline that processes video files with subtitle generation.\"\"\"\n",
    "    \n",
    "    # Define output paths\n",
    "    video_basename = \"video\"  # Using fixed names to avoid string manipulation in pipeline\n",
    "    \n",
    "    output_audio_gcs_path = f\"gs://{output_bucket}/output/audio/{video_basename}.mp3\"\n",
    "    output_transcript_gcs_path = f\"gs://{output_bucket}/output/transcripts/{video_basename}.json\"\n",
    "    output_subtitles_gcs_path = f\"gs://{output_bucket}/output/subtitles/{video_basename}.srt\"\n",
    "    output_video_gcs_path = f\"gs://{output_bucket}/output/videos/{video_basename}_with_subtitles.mp4\"\n",
    "    \n",
    "    # Step 1: Extract audio from video\n",
    "    extract_task = extract_audio_from_video(\n",
    "        input_video_gcs_path=input_video_gcs_path,\n",
    "        output_audio_gcs_path=output_audio_gcs_path\n",
    "    )\n",
    "    \n",
    "    # Step 2: Transcribe audio to text\n",
    "    transcribe_task = transcribe_audio(\n",
    "        audio_gcs_path=extract_task.output,\n",
    "        output_transcript_gcs_path=output_transcript_gcs_path,\n",
    "        language_code=language_code\n",
    "    )\n",
    "    \n",
    "    # Step 3: Generate subtitles from transcription\n",
    "    subtitles_task = generate_subtitles(\n",
    "        transcript_gcs_path=transcribe_task.output,\n",
    "        output_subtitles_gcs_path=output_subtitles_gcs_path\n",
    "    )\n",
    "    \n",
    "    # Step 4: Overlay subtitles on video\n",
    "    overlay_task = overlay_subtitles_on_video(\n",
    "        input_video_gcs_path=input_video_gcs_path,\n",
    "        subtitles_gcs_path=subtitles_task.output,\n",
    "        output_video_gcs_path=output_video_gcs_path\n",
    "    )\n",
    "    \n",
    "    # Return the final output with proper naming\n",
    "    return NamedTuple('Outputs', [('output_video', str)])(overlay_task.output)\n",
    "\n",
    "# STEP 6: Compile the Pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=video_processing_pipeline,\n",
    "    package_path=\"video_processing_pipeline.json\"\n",
    ")\n",
    "\n",
    "print(\"Pipeline compiled successfully to video_processing_pipeline.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f760ad-a412-4458-9eb8-51eb5798e2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
